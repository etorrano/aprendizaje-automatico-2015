{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datos de la entrega"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Número de grupo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Integrantes : Nombre y cédula"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Procesamiento de textos, parte 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(Cada uno de los párrafos numerados requiere de la inserción a continuación de __al menos una__ celda, ya sea de tipo código o texto) *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizaremos procesamiento de textos sobre textos en inglés. El objetivo es determinar el tema del documento, se habla de **categorizar** el documento. Utilizaremos un conjunto de documentos, incluido en la distribución de sklearn, conocido con el nombre **20 Newsgroups** (qwone.com/~jason/20Newsgroups/ ). Se trata de un conjunto de aproximadamente 18.000 mensajes de correo, distribuidos en 20 temas distintos, tales como **religión cristiana**, **ateísmo**, **armas**, **mac hardware**, **computación gráfica**, etc.  Estos temas, a su vez, pueden agruparse entre sí con distintos grados de cercanía. El conjunto ha sido muy utilizado en todo tipo de experimentos de aprendizaje automático y se encuentran disponibles varias implementaciones.\n",
    "\n",
    "En esta tarea se pide que\n",
    "* Lea la documentación presente en la guía del usuario de scikit-learn, sección **5.7** y la documentación en el sitio web, previamente mencionado, sobre el conjunto de datos\n",
    "* Conteste algunas preguntas vinculadas\n",
    "* Realice categorización de subconjuntos del conjunto de datos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1  Inicialice su ambiente importando los módulos necesarios\n",
    "Cargue los datos de entrenamiento del dataset **20 Newsgroups**, con un módulo ya disponible en sklearn, \n",
    "seleccionando 5 categorías distintas, tales que 3 de ellas se encuentren separadas (temas no relacionados) según el esquema del sitio web de 20 Newsgroups y 3 de ellas en el mismo bloque(temas próximos).\n",
    "Despliegue las categorías de los documentos importados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 ¿Cuántos archivos tiene su dataset?\n",
    "Imprima, del 4to archivo, el tema y las 30 primeras líneas.\n",
    "Imprima las categorías de los 1eros 20 documentos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 En cada documento, que es un correo electrónico, hay metadatos (quien envió el correo, fecha, organización, etc.). ¿Los metadatos pueden incidir en la categorización de un documento?\n",
    "¿Por qué puede ser conveniente sacarlos?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 Genere una nueva versión del conjunto de datos, similar al ya generado, pero sin metadatos. Utilice para ello funcionalidades definidas en sklearn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 Un modo de utilizar los datos de texto en aprendizaje es pasar a un modelo vectorial. Explique brevemente como es el modelo vectorial con *bag-of-words*, qué hace *CountVectorizer* definido en sklearn, qué es *tf-idf* y cómo se implementa en Python. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6 Repita el proceso de creación que aparece en el tutorial, llegando a un array \n",
    "que contiene el modelo vectorial para los datos actuales (los documentos seleccionados del dataset original)\n",
    "¿Cuál es el tamaño del vocabulario? ¿Cuál es el largo máximo de un documento? \n",
    "¿Qué conclusiones puede sacar sobre el array que representa a un documento?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7 Resuelva el problema de la categorización con algún algoritmo de aprendizaje (tratando de obtener buenos resultados). Calcule e imprima la medida-F, imprima la matriz de confusión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8 Colapse los documentos con temas relacionados entre sí, asignádoles una única categoría con un nombre adecuado. Resuelva nuevamente el problema de la categorización, con el mismo algoritmo que en el paso anterior y los mismos cálculos de eficiencia. Compare y discuta los resultados. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Procesamiento de textos, parte 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta parte se utilizará otro conjunto muy conocido de datos para aprendizaje, que consiste también de textos en inglés. Se trata de un conjunto de noticias de prensa de la Agencia Reuters, *Reuters-21578 *, https://kdd.ics.uci.edu/databases/reuters21578/reuters21578.html\n",
    "\n",
    "Las noticias han sido categorizadas a mano, con etiquetas de varios tipos, incluyendo *temas, lugares, organizaciones, personas* y otros criterios. Están en formato SGML, las etiquetas aparecen embebidas en el texto. Existe documentación en el archivo README de la distribución.\n",
    "\n",
    "Nos interesaremos en el tipo de etiqueta *temas (en inglés en los textos topics)*. El objetivo es nuevamente aprender los temas a partir de los textos de las noticias, con la diferencia de que este es un problema multi-etiqueta : cada noticia puede tener varios temas. En vez de resolver el problema multi-etiqueta inicial (con más de 100 tópicos distintos) les pedimos que lo transformen según las siguientes simplificaciones: considere solo los 3 temas más frecuentes, y transforme el problema multi-etiqueta en 3 problemas de clasificación binaria\n",
    "\n",
    "No se realiza para esta parte una especificación detallada, sino que les pedimos a Uds. que armen los pasos de una solución y definan el detalle del notebook para esta parte. Mínimamente se espera que procesen la entrada SGML, y encuentren algún modo de enfocar el problema multi-etiqueta en la versión simplificada. Se debe proponer algún modo de tratar el texto, con eventuales mejoras respecto a la vectorización de la parte 1. Se deben aplicar clasificadores y medir su performance, mínimamente con precision, recall y medida-F. Finalmente, se espera una discusión detallada de todo lo realizado y eventuales propuestas de mejora."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
